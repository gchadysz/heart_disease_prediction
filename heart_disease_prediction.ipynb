{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the presence of a heart disease\n",
    "***\n",
    "## Data description\n",
    "The dataset contains medical information about patients from Cleveland, who either suffered or not from a heart disease. The problem analyzed in this project is to try and detect whether a patient has a heart disease or not based on his current condition which is described by a set of variables explained later. The dataset was downloaded from **[here](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)** and is named *processed.cleveland.data*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to import the data and check the dimensions to see what is the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_csv(os.getcwd() + '\\\\processed.cleveland.data', header=None)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 303 observations and 14 variables with one of them being the target variable. Below is the explanation of all of them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* age - patient's age in years\n",
    "* sex - patient's sex (1 = male, 0 = female)\n",
    "* cp - Chest pain type:\n",
    "    * 1 = typical angina\n",
    "    * 2 = atypical angina\n",
    "    * 3 = non-anginal pain\n",
    "    * 4 = asymptomatic\n",
    "* trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n",
    "* chol - serum cholestoral in mg/dl\n",
    "* fbs - fasting blood sugar (if > 120 mg/dl then 1, else 0)\n",
    "* restecg - resting electrocardiographic results:\n",
    "    * 0 = normal\n",
    "    * 1 = having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) \n",
    "    * 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "* thalach - maximum heart rate achieved\n",
    "* exang - exercise induced angina (1 = yes, 0 = no)\n",
    "* oldpeak - ST depression induced by exercise relative to rest\n",
    "* slope - the slope of the peak exercise ST segment:\n",
    "    * 1 = upsloping\n",
    "    * 2 = flat\n",
    "    * 3 = downsloping\n",
    "* ca - number of major vessels colored by flourosopy (values 0 - 3)\n",
    "* thal - a blood disorder called thalassemia:\n",
    "    * 3 = normal\n",
    "    * 6 = fixed defect\n",
    "    * 7 = reversable defect\n",
    "* hds - diagnosis of heart disease (values 0 - 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last variable is the target variable describing whether a patient had a heart disease (values 1 - 4) or didn't (value 0). We would like to create a model which would, in a best way possible, determine if the patient suffers (or not) from a heart disease considering all the measurements and informations we have about him/her.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation and analysis\n",
    "First step is to examine the dataset to get the grasp of how it looks like and how it's constructed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2      3      4    5    6      7    8    9    10   11   12  13\n",
       "0  63.0  1.0  1.0  145.0  233.0  1.0  2.0  150.0  0.0  2.3  3.0  0.0  6.0   0\n",
       "1  67.0  1.0  4.0  160.0  286.0  0.0  2.0  108.0  1.0  1.5  2.0  3.0  3.0   2\n",
       "2  67.0  1.0  4.0  120.0  229.0  0.0  2.0  129.0  1.0  2.6  2.0  2.0  7.0   1\n",
       "3  37.0  1.0  3.0  130.0  250.0  0.0  0.0  187.0  0.0  3.5  3.0  0.0  3.0   0\n",
       "4  41.0  0.0  2.0  130.0  204.0  0.0  2.0  172.0  0.0  1.4  1.0  0.0  3.0   0"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be easier later on to refer to columns with the names of variables, not the numbers, so let's rename the variable names to the ones shown at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = {0:\"age\", 1:\"sex\", 2:\"cp\", 3:\"trestbps\", 4:\"chol\", 5:\"fbs\", 6:\"restecg\", \n",
    "                              7:\"thalach\", 8:\"exang\", 9:\"oldpeak\", 10:\"slope\", 11:\"ca\", 12:\"thal\", 13:\"hds\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check the types of the variables in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         float64\n",
       "sex         float64\n",
       "cp          float64\n",
       "trestbps    float64\n",
       "chol        float64\n",
       "fbs         float64\n",
       "restecg     float64\n",
       "thalach     float64\n",
       "exang       float64\n",
       "oldpeak     float64\n",
       "slope       float64\n",
       "ca           object\n",
       "thal         object\n",
       "hds           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both 'ca' and 'thal' variables are object types, which should not happen. When we take a look at why that is the case we can find out that both of these columns contain non-numeric values. What's more, because of this, rest of the integers is considered as strings and not numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    166\n",
      "7.0    117\n",
      "6.0     18\n",
      "?        2\n",
      "Name: thal, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>hds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "\n",
       "     slope   ca thal  hds  \n",
       "87     1.0  0.0    ?    0  \n",
       "266    2.0  0.0    ?    2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    176\n",
      "1.0     65\n",
      "2.0     38\n",
      "3.0     20\n",
      "?        4\n",
      "Name: ca, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>hds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "166  52.0  1.0  3.0     138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0     132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope ca thal  hds  \n",
       "166    1.0  ?  3.0    0  \n",
       "192    2.0  ?  7.0    1  \n",
       "287    2.0  ?  7.0    0  \n",
       "302    1.0  ?  3.0    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data.thal.value_counts())\n",
    "display(data.loc[data[\"thal\"] == \"?\"])\n",
    "\n",
    "print(data.ca.value_counts())\n",
    "display(data.loc[data[\"ca\"] == \"?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases the missing values were that of nominal variables, thus I decided to impute them with the mode. Most common value seemed like a appropriate method given that in both cases it was quite dominant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    168\n",
      "7.0    117\n",
      "6.0     18\n",
      "Name: thal, dtype: int64\n",
      "0.0    180\n",
      "1.0     65\n",
      "2.0     38\n",
      "3.0     20\n",
      "Name: ca, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data.loc[data[\"thal\"] == \"?\", \"thal\"] = 3\n",
    "data['thal'] = pd.to_numeric(data['thal'])\n",
    "print(data.thal.value_counts())\n",
    "       \n",
    "data.loc[data[\"ca\"] == \"?\", \"ca\"] = 0\n",
    "data['ca'] = pd.to_numeric(data['ca'])\n",
    "print(data.ca.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step we can check if our dataset contains any NAs or has some obvious mistakes in it: i.e. blood pressure equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "hds         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>hds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>4.722772</td>\n",
       "      <td>0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>1.938383</td>\n",
       "      <td>1.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.663366   \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.934375   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal         hds  \n",
       "count  303.000000  303.000000  \n",
       "mean     4.722772    0.937294  \n",
       "std      1.938383    1.228536  \n",
       "min      3.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    2.000000  \n",
       "max      7.000000    4.000000  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.isna().sum())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are no NAs and the descriptive statistics for each column don't show any obvious mistakes or missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have any more missing values we can make an adjustment to the dataset and convert our target variable 'hds' int a binary variable, where lack of a disease is encoded by 0 and a presence of a disease coded as 1. This is due to the fact that we want to discover the presence not to differentiate between their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>hds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  hds  \n",
       "0    3.0  0.0   6.0    0  \n",
       "1    2.0  3.0   3.0    1  \n",
       "2    2.0  2.0   7.0    1  \n",
       "3    3.0  0.0   3.0    0  \n",
       "4    1.0  0.0   3.0    0  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"hds\"] > 0, \"hds\"] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAE/CAYAAADlmNKjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAU7klEQVR4nO3dfZBldX3n8fdHRkAkCQ/TUDgDDpoxiqkksr0samlQDEIwDJvFFKyus0rtVHZRosYHWJNgKuUG8yAum43rGBAkBILGABHjyiKGTZSH5vkpyBSwMBnitAVoUApFv/vH/fXm7niHnunbP6fv8H5V3brnfM/vnPOdrnv7c885t8+kqpAkSYvrWTu6AUmSdkYGrCRJHRiwkiR1YMBKktSBAStJUgcGrCRJHSzb0Q0ALF++vFatWrWj25AkabvceOON36iqqVHLlkTArlq1ipmZmR3dhiRJ2yXJ/9naMk8RS5LUgQErSVIHBqwkSR0YsJIkdWDASpLUgQErSVIHBqwkSR0YsJIkdWDASpLUgQErSVIHBqwkSR0YsJIkdbAkbva/2FaddsWObkHabg+ceeyObkHSIvIIVpKkDgxYSZI6mDdgk5ybZHOSO7aovyPJPUnuTPJ7Q/XTk2xoy17fo2lJkpa6bbkGex7wR8Cn5gpJXgOsAX6mqp5Msl+rHwKcCLwUeB7wv5K8qKq+v9iNS5K0lM17BFtV1wCPbFH+j8CZVfVkG7O51dcAF1fVk1V1P7ABOGwR+5UkaSIs9Brsi4BXJbkuyd8k+ZetvgJ4aGjcxlb7IUnWJZlJMjM7O7vANiRJWpoWGrDLgL2Bw4H3ApckCZARY2vUBqpqfVVNV9X01NTUAtuQJGlpWmjAbgQ+WwPXAz8Alrf6gUPjVgKbxmtRkqTJs9CAvRR4LUCSFwG7At8ALgdOTLJbkoOB1cD1i9GoJEmTZN5vESe5CDgCWJ5kI3AGcC5wbvvTne8Ca6uqgDuTXALcBTwFnOI3iCVJz0TzBmxVnbSVRW/eyvgPAR8apylJkiadd3KSJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqYN6ATXJuks1J7hix7D1JKsnyNp8kZyfZkOS2JIf2aFqSpKVuW45gzwOO3rKY5EDgF4AHh8rHAKvbYx3wsfFblCRp8swbsFV1DfDIiEVnAe8Daqi2BvhUDVwL7JXkgEXpVJKkCbKga7BJjgP+oapu3WLRCuChofmNrSZJ0jPKsu1dIckewAeAo0YtHlGrETWSrGNwGpmDDjpoe9uQJGlJ2+6ABV4IHAzcmgRgJXBTksMYHLEeODR2JbBp1Eaqaj2wHmB6enpkCEtauladdsWObkFakAfOPPZHsp/tPkVcVbdX1X5VtaqqVjEI1UOr6h+By4G3tG8THw58s6oeXtyWJUla+rblz3QuAr4K/FSSjUlOfprhnwfuAzYAnwD+06J0KUnShJn3FHFVnTTP8lVD0wWcMn5bkiRNNu/kJElSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSB/MGbJJzk2xOcsdQ7feT/H2S25L8ZZK9hpadnmRDknuSvL5X45IkLWXbcgR7HnD0FrUrgZ+uqp8BvgacDpDkEOBE4KVtnT9OssuidStJ0oSYN2Cr6hrgkS1qX6yqp9rstcDKNr0GuLiqnqyq+4ENwGGL2K8kSRNhMa7Bvg346za9AnhoaNnGVvshSdYlmUkyMzs7uwhtSJK0dIwVsEk+ADwFXDhXGjGsRq1bVeurarqqpqempsZpQ5KkJWfZQldMshZ4A3BkVc2F6EbgwKFhK4FNC29PkqTJtKAj2CRHA+8Hjquq7wwtuhw4McluSQ4GVgPXj9+mJEmTZd4j2CQXAUcAy5NsBM5g8K3h3YArkwBcW1W/WlV3JrkEuIvBqeNTqur7vZqXJGmpmjdgq+qkEeVznmb8h4APjdOUJEmTzjs5SZLUgQErSVIHBqwkSR0YsJIkdWDASpLUgQErSVIHBqwkSR0YsJIkdWDASpLUgQErSVIHBqwkSR0YsJIkdWDASpLUgQErSVIHBqwkSR0YsJIkdWDASpLUgQErSVIHBqwkSR0YsJIkdWDASpLUgQErSVIHBqwkSR0YsJIkdTBvwCY5N8nmJHcM1fZJcmWSe9vz3q2eJGcn2ZDktiSH9mxekqSlaluOYM8Djt6idhpwVVWtBq5q8wDHAKvbYx3wscVpU5KkyTJvwFbVNcAjW5TXAOe36fOB44fqn6qBa4G9khywWM1KkjQpFnoNdv+qehigPe/X6iuAh4bGbWw1SZKeURb7S04ZUauRA5N1SWaSzMzOzi5yG5Ik7VgLDdivz536bc+bW30jcODQuJXAplEbqKr1VTVdVdNTU1MLbEOSpKVpoQF7ObC2Ta8FLhuqv6V9m/hw4Jtzp5IlSXomWTbfgCQXAUcAy5NsBM4AzgQuSXIy8CDwxjb888AvAhuA7wBv7dCzJElL3rwBW1UnbWXRkSPGFnDKuE1JkjTpvJOTJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSBwasJEkdGLCSJHVgwEqS1IEBK0lSB2MFbJJ3JbkzyR1JLkqye5KDk1yX5N4kf55k18VqVpKkSbHggE2yAjgVmK6qnwZ2AU4EPgycVVWrgUeBkxejUUmSJsm4p4iXAc9JsgzYA3gYeC3wmbb8fOD4MfchSdLEWXDAVtU/AH8APMggWL8J3Ag8VlVPtWEbgRXjNilJ0qQZ5xTx3sAa4GDgecBzgWNGDK2trL8uyUySmdnZ2YW2IUnSkjTOKeLXAfdX1WxVfQ/4LPAKYK92yhhgJbBp1MpVtb6qpqtqempqaow2JElaesYJ2AeBw5PskSTAkcBdwNXACW3MWuCy8VqUJGnyjHMN9joGX2a6Cbi9bWs98H7g3Uk2APsC5yxCn5IkTZRl8w/Zuqo6Azhji/J9wGHjbFeSpEnnnZwkSerAgJUkqQMDVpKkDgxYSZI6MGAlSerAgJUkqQMDVpKkDgxYSZI6MGAlSerAgJUkqQMDVpKkDgxYSZI6MGAlSerAgJUkqQMDVpKkDgxYSZI6MGAlSerAgJUkqQMDVpKkDgxYSZI6MGAlSerAgJUkqQMDVpKkDgxYSZI6MGAlSepgrIBNsleSzyT5+yR3J3l5kn2SXJnk3va892I1K0nSpBj3CPa/Al+oqhcDPwvcDZwGXFVVq4Gr2rwkSc8oCw7YJD8OvBo4B6CqvltVjwFrgPPbsPOB48dtUpKkSTPOEewLgFngk0luTvInSZ4L7F9VDwO05/1GrZxkXZKZJDOzs7NjtCFJ0tIzTsAuAw4FPlZVLwO+zXacDq6q9VU1XVXTU1NTY7QhSdLSM07AbgQ2VtV1bf4zDAL360kOAGjPm8drUZKkybPggK2qfwQeSvJTrXQkcBdwObC21dYCl43VoSRJE2jZmOu/A7gwya7AfcBbGYT2JUlOBh4E3jjmPiRJmjhjBWxV3QJMj1h05DjblSRp0nknJ0mSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA4MWEmSOjBgJUnqwICVJKkDA1aSpA7GDtgkuyS5Ocnn2vzBSa5Lcm+SP0+y6/htSpI0WRbjCPbXgLuH5j8MnFVVq4FHgZMXYR+SJE2UsQI2yUrgWOBP2nyA1wKfaUPOB44fZx+SJE2icY9gPwq8D/hBm98XeKyqnmrzG4EVY+5DkqSJs+CATfIGYHNV3ThcHjG0trL+uiQzSWZmZ2cX2oYkSUvSOEewrwSOS/IAcDGDU8MfBfZKsqyNWQlsGrVyVa2vqumqmp6amhqjDUmSlp4FB2xVnV5VK6tqFXAi8KWqehNwNXBCG7YWuGzsLiVJmjA9/g72/cC7k2xgcE32nA77kCRpSVs2/5D5VdWXgS+36fuAwxZju5IkTSrv5CRJUgcGrCRJHRiwkiR1YMBKktSBAStJUgcGrCRJHRiwkiR1YMBKktSBAStJUgcGrCRJHRiwkiR1YMBKktSBAStJUgcGrCRJHRiwkiR1YMBKktSBAStJUgcGrCRJHRiwkiR1YMBKktSBAStJUgcGrCRJHRiwkiR1YMBKktSBAStJUgcLDtgkBya5OsndSe5M8mutvk+SK5Pc2573Xrx2JUmaDOMcwT4F/HpVvQQ4HDglySHAacBVVbUauKrNS5L0jLLggK2qh6vqpjb9T8DdwApgDXB+G3Y+cPy4TUqSNGkW5RpsklXAy4DrgP2r6mEYhDCw31bWWZdkJsnM7OzsYrQhSdKSMXbAJtkT+AvgnVX1rW1dr6rWV9V0VU1PTU2N24YkSUvKWAGb5NkMwvXCqvpsK389yQFt+QHA5vFalCRp8ozzLeIA5wB3V9VHhhZdDqxt02uByxbeniRJk2nZGOu+Evh3wO1Jbmm1/wycCVyS5GTgQeCN47UoSdLkWXDAVtXfAtnK4iMXul1JknYG3slJkqQODFhJkjowYCVJ6sCAlSSpAwNWkqQODFhJkjowYCVJ6sCAlSSpAwNWkqQODFhJkjowYCVJ6sCAlSSpAwNWkqQODFhJkjowYCVJ6sCAlSSpAwNWkqQODFhJkjowYCVJ6sCAlSSpAwNWkqQODFhJkjowYCVJ6sCAlSSpg24Bm+ToJPck2ZDktF77kSRpKeoSsEl2Af47cAxwCHBSkkN67EuSpKWo1xHsYcCGqrqvqr4LXAys6bQvSZKWnF4BuwJ4aGh+Y6tJkvSMsKzTdjOiVv/fgGQdsK7NPp7knk69aHEtB76xo5vYGeXDO7oDLSG+zzpa5Pfa87e2oFfAbgQOHJpfCWwaHlBV64H1nfavTpLMVNX0ju5D2pn5Pts59DpFfAOwOsnBSXYFTgQu77QvSZKWnC5HsFX1VJK3A/8T2AU4t6ru7LEvSZKWol6niKmqzwOf77V97TCe1pf68322E0hVzT9KkiRtF2+VKElSBwbsTiJJJfnDofn3JPngGNt7IMnyNv2VRWhRWlKSfD/JLUnuTHJrkncneVZbNp3k7B3d41KSZFWSf7uj+5gkBuzO40ngl+dCcTFV1SsWe5vSEvBEVf1cVb0U+AXgF4EzAKpqpqpO3aHdbYd2e9reVgEG7HYwYHceTzH4YsS7tlyQ5PlJrkpyW3s+aMSYfZN8McnNST7O0M1Ckjzeng9Ick371H9Hkle1+lFJvprkpiSfTrJnq/9Wkhva2PVJ0uqnJrmr9XNxqz03yblt/M1JvLWmfmSqajODG9+8PQNHJPkcQJKfb6/5W9pr88da/b3t9Xpbkt+e21aSS5Pc2I6M17XaLknOa++F25O8q9VfmOQLbfz/TvLiLXtL8sEkFyT5UpJ7k/yHVj8iydVJ/gy4vdXenOT61uvH2363a99t7NlJvpLkviQntFbOBF7Vtv1Dv2c0QlX52AkewOPAjwMPAD8BvAf4YFv2V8DaNv024NIR658N/FabPpbBnbeWz227Pf868IE2vQvwYwzuOHMN8NxWf//QdvYZ2v4FwC+16U3Abm16r/b8X4A3z9WAr81t04ePHo+51/UWtUeB/YEjgM+12l8Br2zTezL464ujGHygDYMDlc8Br25j9mnPzwHuAPYF/gVw5dB+5l73VwGr2/S/Ar40oqcPAre27S1ncBva57Uevw0c3Ma9pPX67Db/x8BbtnffwHnAp9u/6xAG95Vn+GfiY9se3f5MRz96VfWtJJ8CTgWeGFr0cuCX2/QFwO+NWP3Vc2Oq6ookj44YcwNwbpJnMwjpW5L8PIM34d+1A9Rdga+28a9J8j5gD2Af4E4GvwBuAy5McilwaRt7FHBckve0+d2Bg4C7t+NHII1r1G1e/w74SJILgc9W1cYkRzF4zd7cxuwJrGbwYfPUJP+61Q9s9XuAFyT5b8AVwBfbmZ5XAJ9u7x2A3bbS12VV9QTwRJKrGfyHKo8B11fV/W3MkQzC9Ia2vecAmxm857Z335dW1Q+Au5Lsv/Ufl56OAbvz+ShwE/DJpxmztb/Netq/2aqqa5K8msER7gVJfp/BJ/4rq+qk4bFJdmfwCXq6qh7K4AtXu7fFxzII9OOA30zyUga/2P5NVXlPau0QSV4AfJ9BKL1krl5VZya5gsE12muTvI7B6/V3q+rjW2zjCOB1wMur6jtJvgzsXlWPJvlZ4PXAKcCvAO8EHquqn9uG9rZ8b87Nf3t498D5VXX6iH/b9u77yS22qwXwGuxOpqoeAS4BTh4qf4XB7SoB3gT87YhVr2nLSHIMsPeWA5I8H9hcVZ8AzgEOBa4FXpnkJ9uYPZK8iH8O02+0T8sntOXPAg6sqquB9zE4Hbwng7t+vWPoOu3LFvQDkBYgyRTwP4A/qnY+dGjZC6vq9qr6MDADvJjB6/VtQ983WJFkPwaXZx5t4fpi4PC2fDnwrKr6C+A3gUOr6lvA/Une2MakBeEoa5LsnmRfBqdqbxgx5irghNYHSfbJ4PsX4+57zj8xuCykbeQR7M7pD4G3D82fyuDU7nuBWeCtI9b5beCiJDcBfwM8OGLMEcB7k3yPwTXft1TVbJJ/39adO8X0G1X1tSSfYPDliwf4518IuwB/muQnGHwyPquqHkvyOwyOvm9rIfsA8IaF/OOlbfScJLcAz2bwJcELgI+MGPfOJK9hcHR7F/DXVfVkkpcAX22fCR8H3gx8AfjVJLcxOC18bdvGCuCT7QMmwNxR5puAjyX5jdbHxQyut27pegandw8CfqeqNrUPsv9PVd3VtvPFtp/vMThifWLMfc+5DXgqya3AeVV11tOMFd7JSZKWtHZ55fGq+oMd3Yu2j6eIJUnqwCNYSZI68AhWkqQODFhJkjowYCVJ6sCAlSSpAwNWkqQODFhJkjr4v6XEHvaD137dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "values = [\"No disease\", \"Disease present\"]\n",
    "counts = data.hds.value_counts()\n",
    "\n",
    "ax.bar(values, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the number of patients with and without heart disease is more or less balanced across the dataset. What would probably be interesting is how the presence of the heart disease is distributed among certain ages. We can see it on the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23636b1eac8>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_disease_age = data.loc[data[\"hds\"] == 0, \"age\"].value_counts()\n",
    "disease_age = data.loc[data[\"hds\"] == 1, \"age\"].value_counts()\n",
    "\n",
    "bar_data = pd.concat([no_disease_age, disease_age], axis=1)\n",
    "bar_data.columns = [\"No disease\", \"Disease present\"]\n",
    "\n",
    "bar_data.plot.bar(figsize=(14,7), stacked = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that up until the age of 55 the percentage of patients with no disease is higher than those with disease, but at the age of 55 till the age of 64 the tendency is opposite. After that it varies but the sample sizes of elder people are also getting smaller so it's not as objective as with the bigger samples.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "In this chapter I will try and estimate 3 different types of models, that is: KNN, SVM and Logistic Regression. A comparison of those 3 methods could potentially give some interesting insight as well as enable us to compare their predictive power. In order to get good results we must first conduct binarization of nominal variables and possibly standarization of numerical ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "In order to use KNN efficiently we will first one-hot encode all the nominal variables from our dataset and standardize numerical ones. Then we will try to estimate KNN model for a dataset with standardized numerical variables and for the one without and see which yields better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>ca_1.0</th>\n",
       "      <th>ca_2.0</th>\n",
       "      <th>ca_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>sex</th>\n",
       "      <th>exang</th>\n",
       "      <th>fbs</th>\n",
       "      <th>hds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947160</td>\n",
       "      <td>0.756274</td>\n",
       "      <td>-0.264463</td>\n",
       "      <td>0.017169</td>\n",
       "      <td>1.085542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.389703</td>\n",
       "      <td>1.608559</td>\n",
       "      <td>0.759159</td>\n",
       "      <td>-1.818896</td>\n",
       "      <td>0.396526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.389703</td>\n",
       "      <td>-0.664201</td>\n",
       "      <td>-0.341717</td>\n",
       "      <td>-0.900864</td>\n",
       "      <td>1.343924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.929372</td>\n",
       "      <td>-0.096011</td>\n",
       "      <td>0.063869</td>\n",
       "      <td>1.634655</td>\n",
       "      <td>2.119067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.486829</td>\n",
       "      <td>-0.096011</td>\n",
       "      <td>-0.824558</td>\n",
       "      <td>0.978917</td>\n",
       "      <td>0.310399</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  trestbps      chol   thalach   oldpeak  cp_2.0  cp_3.0  cp_4.0  \\\n",
       "0  0.947160  0.756274 -0.264463  0.017169  1.085542       0       0       0   \n",
       "1  1.389703  1.608559  0.759159 -1.818896  0.396526       0       0       1   \n",
       "2  1.389703 -0.664201 -0.341717 -0.900864  1.343924       0       0       1   \n",
       "3 -1.929372 -0.096011  0.063869  1.634655  2.119067       0       1       0   \n",
       "4 -1.486829 -0.096011 -0.824558  0.978917  0.310399       1       0       0   \n",
       "\n",
       "   restecg_1.0  restecg_2.0  ...  slope_3.0  ca_1.0  ca_2.0  ca_3.0  thal_6.0  \\\n",
       "0            0            1  ...          1       0       0       0         1   \n",
       "1            0            1  ...          0       0       0       1         0   \n",
       "2            0            1  ...          0       0       1       0         0   \n",
       "3            0            0  ...          1       0       0       0         0   \n",
       "4            0            1  ...          0       0       0       0         0   \n",
       "\n",
       "   thal_7.0  sex  exang  fbs  hds  \n",
       "0         0  1.0    0.0  1.0    0  \n",
       "1         0  1.0    1.0  0.0    1  \n",
       "2         1  1.0    1.0  0.0    1  \n",
       "3         0  1.0    0.0  0.0    0  \n",
       "4         0  0.0    0.0  0.0    0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>ca_1.0</th>\n",
       "      <th>ca_2.0</th>\n",
       "      <th>ca_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>sex</th>\n",
       "      <th>exang</th>\n",
       "      <th>fbs</th>\n",
       "      <th>hds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  trestbps   chol  thalach  oldpeak  cp_2.0  cp_3.0  cp_4.0  \\\n",
       "0  63.0     145.0  233.0    150.0      2.3       0       0       0   \n",
       "1  67.0     160.0  286.0    108.0      1.5       0       0       1   \n",
       "2  67.0     120.0  229.0    129.0      2.6       0       0       1   \n",
       "3  37.0     130.0  250.0    187.0      3.5       0       1       0   \n",
       "4  41.0     130.0  204.0    172.0      1.4       1       0       0   \n",
       "\n",
       "   restecg_1.0  restecg_2.0  ...  slope_3.0  ca_1.0  ca_2.0  ca_3.0  thal_6.0  \\\n",
       "0            0            1  ...          1       0       0       0         1   \n",
       "1            0            1  ...          0       0       0       1         0   \n",
       "2            0            1  ...          0       0       1       0         0   \n",
       "3            0            0  ...          1       0       0       0         0   \n",
       "4            0            1  ...          0       0       0       0         0   \n",
       "\n",
       "   thal_7.0  sex  exang  fbs  hds  \n",
       "0         0  1.0    0.0  1.0    0  \n",
       "1         0  1.0    1.0  0.0    1  \n",
       "2         1  1.0    1.0  0.0    1  \n",
       "3         0  1.0    0.0  0.0    0  \n",
       "4         0  0.0    0.0  0.0    0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nominal = data[[\"cp\", \"restecg\", \"slope\", \"ca\", \"thal\"]].astype(object)\n",
    "numerical = data[[\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]]\n",
    "\n",
    "dummy = pd.get_dummies(nominal, drop_first=True)\n",
    "print(dummy.shape)\n",
    "\n",
    "numerical_std = numerical.apply(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "data_bin = pd.concat([numerical, dummy, data[[\"sex\", \"exang\", \"fbs\", \"hds\"]]], axis=1)\n",
    "data_bin_norm = pd.concat([numerical_std, dummy, data[[\"sex\", \"exang\", \"fbs\", \"hds\"]]], axis=1)\n",
    "display(data_bin_norm.head())\n",
    "display(data_bin.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the standarization and one-hot encoding sorted out we can take a look at the KNN model with all the variables and find out what is the optimal number of neighbors. We take into consideration numbers from 1 to 17 since we have 303 rows  and 17 is closest square root of that number. We also split the data into 70% train set and 30% test set. We then perform grid search across the range of values of neighbors. What it does is it performs, in our case, a 5-fold cross validation on the training set, finds the hyperparameter value for which the mean test accuracy of those cross validations is the highest. We can then use the model with that hyperparameter to predict on the test data, which wasn't used in the cross validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also create a dataframe to store the metrics of our models in one place so that they are easily comparable. For that I chose two metrics, ROC area under curve score and accuracy, which should be a good metric in our case, since we don't have the case of having drastically imbalanced target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = [\"Model\", \"ROC AUC score\", \"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will try and predict using only binarized data, with numerical values intact. Then we will compare the results with binarized and standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned KNN number of neighbors: {'n_neighbors': 5} \n",
      "\n",
      "[[36 16]\n",
      " [17 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69        52\n",
      "           1       0.58      0.56      0.57        39\n",
      "\n",
      "    accuracy                           0.64        91\n",
      "   macro avg       0.63      0.63      0.63        91\n",
      "weighted avg       0.64      0.64      0.64        91\n",
      "\n",
      "ROC AUC score: 0.6282051282051282\n",
      "Test accuracy: 0.6373626373626373\n",
      "Train accuracy: 0.7452830188679245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "y_norm = data_bin['hds'].values\n",
    "X_norm = data_bin.drop('hds', axis = 1).values\n",
    "\n",
    "neighbors = np.arange(1, 18)\n",
    "param_grid = {'n_neighbors': neighbors}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size = 0.3, random_state = 2020)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv = 5, iid = True)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "y_pred = knn_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned KNN number of neighbors: {} \\n\".format(knn_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(knn_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(knn_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can clearly see the results are far from satisfying with barely 63% accuracy. Also the train accuracy is significantly higher tha test accuracy which may suggest a model overfitting. Let's try estimating again using standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned KNN number of neighbors: {'n_neighbors': 6} \n",
      "\n",
      "[[49  3]\n",
      " [12 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87        52\n",
      "           1       0.90      0.69      0.78        39\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.85      0.82      0.82        91\n",
      "weighted avg       0.84      0.84      0.83        91\n",
      "\n",
      "ROC AUC score: 0.8173076923076923\n",
      "Test accuracy: 0.8351648351648352\n",
      "Train accuracy: 0.8018867924528302\n"
     ]
    }
   ],
   "source": [
    "y_norm = data_bin_norm['hds'].values\n",
    "X_norm = data_bin_norm.drop('hds', axis = 1).values\n",
    "\n",
    "neighbors = np.arange(1, 18)\n",
    "param_grid = {'n_neighbors': neighbors}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size = 0.3, random_state = 2020)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv = 5, iid = True)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "y_pred = knn_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned KNN number of neighbors: {} \\n\".format(knn_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(knn_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(knn_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"KNN-6\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": knn_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe a significant improvement in predictiong power of the KNN algorithm and so we will stick with the second dataset for the rest of the project. As far as the above model is concerned the optimal number of parameters which yields the highest accuracy is for 6 neighbors. We can also see a confusion matrix which tells us how our model classified observations from the test set. We have 49 TPs, 3 FPs, 12 FNs and 27 TNs. That means our model predicted correctly 76 (TP + TN) out of 91 patients. From 15 wrongly predicted, 3 are those which didn't have disease but were predicted to have and 12 are those which have disease but were predicted as if they had not. This seems to be the biggest weakness of this particular model. It is shown directly by the recall value for 1 (0.69), which is significantly smaller than the rest of the metrics. The ROC area under curve on test data also is equal to 0.81, which isn't a bad result but can probably be improved. Last output shows us both the test and train set accuracies, which are fairly similar, so there seems to be neither overfitting nor underfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "Second model we will be performing is a Support Vector Machine. Following the pattern of KNN it benefits from having the supplied data binarized and standardized. However, SVMs can be linear and non-linear so we will check which one of them is better suited to our data. This time, the parameter passed to param_grid, along which GridSearchCV searches the best accuracy, is 'C' parameter standing for regularization. The boundaries for the range of values for parameters were narrowed down by previously testing different values, so that the computation wouldn't take ages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C parameter: {'C': 4.899999999999998} \n",
      "\n",
      "[[49  3]\n",
      " [ 9 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        52\n",
      "           1       0.91      0.77      0.83        39\n",
      "\n",
      "    accuracy                           0.87        91\n",
      "   macro avg       0.88      0.86      0.86        91\n",
      "weighted avg       0.87      0.87      0.87        91\n",
      "\n",
      "ROC AUC score: 0.8557692307692306\n",
      "Test accuracy: 0.8681318681318682\n",
      "Train accuracy: 0.8679245283018868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "c = np.arange(1, 7, 0.15)\n",
    "param_grid = {'C': c}\n",
    "\n",
    "svc = SVC(cache_size = 500, kernel = 'linear',\n",
    "          max_iter = -1, probability = True)\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv = 5, iid = True)\n",
    "svc_cv.fit(X_train, y_train)\n",
    "y_pred = svc_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C parameter: {} \\n\".format(svc_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(svc_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(svc_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"SVM linear\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": svc_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can see from the output is that the linear version of svm produces better results than KNN algorithm altogether. The tuned paramter for which the accuracy is the highest is 4.9. Test and train accuracy are almost equal to each other and the ROC AUC score higher by around 0.04 in comparison to KNN. The model definitely improved in terms of predictin diseased patients, as it predictet 3 more TNs. The number of TPs stayed the same as previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next on we will try both 'poly' and 'rbf' kernels to try and see if the results are any better than for linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C and degree parameters: {'C': 3.3999999999999986, 'degree': 2} \n",
      "\n",
      "[[50  2]\n",
      " [12 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88        52\n",
      "           1       0.93      0.69      0.79        39\n",
      "\n",
      "    accuracy                           0.85        91\n",
      "   macro avg       0.87      0.83      0.84        91\n",
      "weighted avg       0.86      0.85      0.84        91\n",
      "\n",
      "ROC AUC score: 0.826923076923077\n",
      "Test accuracy: 0.8461538461538461\n",
      "Train accuracy: 0.8584905660377359\n"
     ]
    }
   ],
   "source": [
    "c = np.arange(1, 7, 0.15)\n",
    "degree = np.arange(2, 6, 1)\n",
    "param_grid = {'C': c, 'degree': degree}\n",
    "\n",
    "svc = SVC(cache_size = 500, kernel = 'poly', max_iter = -1, \n",
    "          probability = True, gamma = 'auto')\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv = 5, iid = True)\n",
    "svc_cv.fit(X_train, y_train)\n",
    "y_pred = svc_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C and degree parameters: {} \\n\".format(svc_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(svc_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(svc_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"SVM poly\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": svc_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'poly' kernel and searching through the same values of 'C' and degress from set [2,3,4,5], we can see that there is no combination of those two parameters that yields better overall results than linear kernel. However, this particular model is even better than previous two at predicting healthy people correctly. It could potentially be useful at dissmissing healthy patients so that the staff may focus on finding the sick within the rest. The optimal 'C' is 3.4 and number of degrees is 2. All in all, though, almost all the model's metrics decreased and it is rather a less useful model than linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C parameter: {'C': 0.3} \n",
      "\n",
      "[[46  6]\n",
      " [ 8 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87        52\n",
      "           1       0.84      0.79      0.82        39\n",
      "\n",
      "    accuracy                           0.85        91\n",
      "   macro avg       0.84      0.84      0.84        91\n",
      "weighted avg       0.85      0.85      0.85        91\n",
      "\n",
      "ROC AUC score: 0.8397435897435896\n",
      "Test accuracy: 0.8461538461538461\n",
      "Train accuracy: 0.8254716981132075\n"
     ]
    }
   ],
   "source": [
    "c = np.arange(0.05, 3, 0.05)\n",
    "param_grid = {'C': c}\n",
    "\n",
    "svc = SVC(cache_size = 500, kernel = 'rbf', max_iter = -1, \n",
    "          probability = True, gamma = 'auto')\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv = 5, iid = True)\n",
    "svc_cv.fit(X_train, y_train)\n",
    "y_pred = svc_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C parameter: {} \\n\".format(svc_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(svc_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(svc_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"SVM rbf\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": svc_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a 'rbf' kernel we got rid of degrees parameter since according to sklearn documentation degree parameter is ignored by all kernels apart from 'poly'. Thus we performed a grid search cross-validation only with respect to 'C' parameter. The optimal value was set to 0.3, for which the SVM's ROC AUC score and accuracy were worse than that of linear SVM's but better than KNNs and poly SVMs. Current model got worse at predicting healthy people, since now it predicts 6 of them wrongly. However it got better at predicting sick people, since now it predicts 31 out of 39 correctly which I think can be seen as improvement. Treating a healthy patient has less severe consequences than not treating a sick one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Last classification model that is going to be used in this project is logistic regression. As with previous models, the data is binarized and standardized. In our first step we would like to determine which regularization (Lasso or Ridge) would provide better results. To check this we assign both the parameter 'C' and two types of penalties to the parameter grid, 'l1' being Lasso regression and 'l2' being Ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C and penalty parameters: {'C': 1.2648552168552958, 'penalty': 'l1'} \n",
      "\n",
      "[[48  4]\n",
      " [ 6 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        52\n",
      "           1       0.89      0.85      0.87        39\n",
      "\n",
      "    accuracy                           0.89        91\n",
      "   macro avg       0.89      0.88      0.89        91\n",
      "weighted avg       0.89      0.89      0.89        91\n",
      "\n",
      "ROC AUC score: 0.8846153846153848\n",
      "Test accuracy: 0.8901098901098901\n",
      "Train accuracy: 0.8726415094339622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c_log = np.logspace(-5, 5, 50)\n",
    "param_grid = {'C': c_log, 'penalty': ['l1','l2']}\n",
    "\n",
    "lr = LogisticRegression(solver = 'saga', max_iter = 100000)\n",
    "lr_cv = GridSearchCV(lr, param_grid, cv = 5, iid = True)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "y_pred = lr_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C and penalty parameters: {} \\n\".format(lr_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(lr_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(lr_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"Logreg Lasso\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": lr_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the best results are obtained for 'C' equal to 1.26 and when l1 (Lasso) regularization is applied. Since Lasso is a form of variable selection and Ridge is not, it may suggest that we may have some variables whose removal would improve the model. The results are slightly worse at predicting healthy patients than poly SVM (two fewer TP predictions), but also slightly better at predicting sick patients (two TN predicted than for rbf SVM). The model follows previous tendency of smaller recall for 1's. Arguably it is the best model up to this moment, with both highest accuracy, ROC AUC score and detection rate for sick patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression provides the possibilty of mixing L1 and L2 standarizations in a form of ElasticNet, which is a weighted combination of previous two - 'l1_ratio' being the weight of L1 regularization and 1-'l1_ratio' the weight of L2 regularization. We will try and see if it provides anything more to the results. The range of 'l1-ratio' was also previously tested and narrowed down to reduce the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C and l1_ratio parameters: {'C': 2.0235896477251556, 'l1_ratio': 0.0} \n",
      "\n",
      "[[49  3]\n",
      " [ 7 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        52\n",
      "           1       0.91      0.82      0.86        39\n",
      "\n",
      "    accuracy                           0.89        91\n",
      "   macro avg       0.89      0.88      0.89        91\n",
      "weighted avg       0.89      0.89      0.89        91\n",
      "\n",
      "ROC AUC score: 0.8814102564102564\n",
      "Test accuracy: 0.8901098901098901\n",
      "Train accuracy: 0.8726415094339622\n"
     ]
    }
   ],
   "source": [
    "c_log = np.logspace(-5, 5, 50)\n",
    "l1_ratio = np.arange(0, 0.2, 0.05)\n",
    "param_grid = {'C': c_log, 'l1_ratio': l1_ratio}\n",
    "\n",
    "lr = LogisticRegression(solver = 'saga', penalty = 'elasticnet', max_iter = 10000000)\n",
    "lr_cv = GridSearchCV(lr, param_grid, cv = 5, iid = True)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "y_pred = lr_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C and l1_ratio parameters: {} \\n\".format(lr_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(lr_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(lr_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"Logreg ElasticNet\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": lr_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying many different parameter ranges for l1_ratio the one above gave the best results in terms of ROC AUC score and accuracy. The output suggests that the L1 regularization should not be used at all to get the best results. The ElasticNet turned, in fact, into a Ridge regression (with 'C' parameter equal to 2.02) which also predicted 10 patients in total wrongly, same as previous Lasso regression. However it is worse at predicting true negatives. So we can say that it is very close in terms of overall usefulness, but falls just a bit short due to aforementioned importance of true negative detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have obtained predictions using a few different methods and below we have a summary of how each model fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Model  ROC AUC score  Accuracy\n",
      "             KNN-6       0.817308  0.835165\n",
      "        SVM linear       0.855769  0.868132\n",
      "          SVM poly       0.826923  0.846154\n",
      "           SVM rbf       0.839744  0.846154\n",
      "      Logreg Lasso       0.884615  0.890110\n",
      " Logreg ElasticNet       0.881410  0.890110\n"
     ]
    }
   ],
   "source": [
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in terms of both ROC AUC score and accuracy are generally very much alike, with KNN and poly SVM models falling a bit short. All in all though, here is current list of models with highest score and accuracy:\n",
    "1. Logreg Lasso\n",
    "2. Logreg ElasticNet\n",
    "3. SVM linear\n",
    "4. SVM rbf\n",
    "6. SVM poly\n",
    "7. KNN-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "All the previous models were calculated with all variables taken into consideration. Now we will take a look at feature selection to try and determine whether we can obtain better results if we omit certain variables. First off, let's take a look at the mutual information statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal variables:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['cp', array([0.12506337])],\n",
       " ['restecg', array([0.01978269])],\n",
       " ['slope', array([0.07265731])],\n",
       " ['ca', array([0.13758927])],\n",
       " ['thal', array([0.10760075])],\n",
       " ['sex', array([0.01412752])],\n",
       " ['exang', array([0.09035399])],\n",
       " ['fbs', array([0])]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variables:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['age', array([0.01754789])],\n",
       " ['trestbps', array([0])],\n",
       " ['chol', array([0.07485494])],\n",
       " ['thalach', array([0.08261985])],\n",
       " ['oldpeak', array([0.11335987])]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nominal = [\"cp\", \"restecg\", \"slope\", \"ca\", \"thal\", \"sex\", \"exang\", \"fbs\"]\n",
    "numerical = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
    "\n",
    "from sklearn import feature_selection\n",
    "\n",
    "mutual_info_nominal = []\n",
    "for var in nominal:\n",
    "    mi = feature_selection.mutual_info_classif(data[var].values.reshape(-1,1), data[\"hds\"].values, random_state = 2020)\n",
    "    mutual_info_nominal.append([var, mi])\n",
    "\n",
    "mutual_info_numerical = []\n",
    "for var in numerical:\n",
    "    mi = feature_selection.mutual_info_classif(data[var].values.reshape(-1,1), data[\"hds\"].values, random_state = 2020)\n",
    "    mutual_info_numerical.append([var, mi])\n",
    "\n",
    "print(\"Nominal variables:\")\n",
    "display(mutual_info_nominal)\n",
    "print(\"Numerical variables:\")\n",
    "display(mutual_info_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can see, variables 'fbs' and 'trestbps' are the ones with lowest values. Next in order are 'restecg', 'age' and 'sex' with values below 0.02. We can now try and calculate logistic regressions without these 'insignificant' variables to see whether it improves the model. We must alter our dataset accordingly first. We remove 'fbs' and 'trestbps' from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>age</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>ca_1.0</th>\n",
       "      <th>ca_2.0</th>\n",
       "      <th>ca_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang</th>\n",
       "      <th>hds</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.264463</td>\n",
       "      <td>0.017169</td>\n",
       "      <td>1.085542</td>\n",
       "      <td>0.947160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759159</td>\n",
       "      <td>-1.818896</td>\n",
       "      <td>0.396526</td>\n",
       "      <td>1.389703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.341717</td>\n",
       "      <td>-0.900864</td>\n",
       "      <td>1.343924</td>\n",
       "      <td>1.389703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063869</td>\n",
       "      <td>1.634655</td>\n",
       "      <td>2.119067</td>\n",
       "      <td>-1.929372</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.824558</td>\n",
       "      <td>0.978917</td>\n",
       "      <td>0.310399</td>\n",
       "      <td>-1.486829</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chol   thalach   oldpeak       age  cp_2.0  cp_3.0  cp_4.0  slope_2.0  \\\n",
       "0 -0.264463  0.017169  1.085542  0.947160       0       0       0          0   \n",
       "1  0.759159 -1.818896  0.396526  1.389703       0       0       1          1   \n",
       "2 -0.341717 -0.900864  1.343924  1.389703       0       0       1          1   \n",
       "3  0.063869  1.634655  2.119067 -1.929372       0       1       0          0   \n",
       "4 -0.824558  0.978917  0.310399 -1.486829       1       0       0          0   \n",
       "\n",
       "   slope_3.0  ca_1.0  ca_2.0  ca_3.0  thal_6.0  thal_7.0  restecg_1.0  \\\n",
       "0          1       0       0       0         1         0            0   \n",
       "1          0       0       0       1         0         0            0   \n",
       "2          0       0       1       0         0         1            0   \n",
       "3          1       0       0       0         0         0            0   \n",
       "4          0       0       0       0         0         0            0   \n",
       "\n",
       "   restecg_2.0  exang  hds  sex  \n",
       "0            1    0.0    0  1.0  \n",
       "1            1    1.0    1  1.0  \n",
       "2            1    1.0    1  1.0  \n",
       "3            0    0.0    0  1.0  \n",
       "4            1    0.0    0  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nominal_fs = data[[\"cp\", \"slope\", \"ca\", \"thal\", \"restecg\"]].astype(object)\n",
    "numerical_fs = data[[\"chol\", \"thalach\", \"oldpeak\", \"age\"]]\n",
    "\n",
    "dummy_fs = pd.get_dummies(nominal_fs, drop_first=True)\n",
    "numerical_std_fs = numerical_fs.apply(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "data_bin_norm_fs = pd.concat([numerical_std_fs, dummy_fs, data[[\"exang\", \"hds\", \"sex\"]]], axis=1)\n",
    "\n",
    "display(data_bin_norm_fs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS K-Nearest Neighbors\n",
    "Now we can perform the same algorithms as before for our feature selected dataset and see whether there are any improvements to the predictions. All the models from before will be used on the feature selected data, as they would most likely achieve different scores and it could be useful knowing which improved and which regressed in terms of performance and prediction power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned KNN number of neighbors: {'n_neighbors': 3} \n",
      "\n",
      "[[47  5]\n",
      " [ 8 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88        52\n",
      "           1       0.86      0.79      0.83        39\n",
      "\n",
      "    accuracy                           0.86        91\n",
      "   macro avg       0.86      0.85      0.85        91\n",
      "weighted avg       0.86      0.86      0.86        91\n",
      "\n",
      "ROC AUC score: 0.8493589743589743\n",
      "Test accuracy: 0.8571428571428571\n",
      "Train accuracy: 0.8537735849056604\n"
     ]
    }
   ],
   "source": [
    "y_norm_fs = data_bin_norm_fs['hds'].values\n",
    "X_norm_fs = data_bin_norm_fs.drop('hds', axis = 1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm_fs, y_norm_fs, test_size = 0.3, random_state = 2020)\n",
    "\n",
    "neighbors = np.arange(1, 18)\n",
    "param_grid = {'n_neighbors': neighbors}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv = 5, iid = True)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "y_pred = knn_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned KNN number of neighbors: {} \\n\".format(knn_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(knn_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(knn_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"FS KNN-3\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": knn_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there is an overall improvement to the previous KNN model, with 4 more good predictions of sick patients and only two worse for healthy patients. Feature selection successfully detected insignificant variables and their omission turned out to improve the model. In terms of metrics it is now better than both poly and rbf SVMs and just slightly worse than linear SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS SVM\n",
    "From the SVM 'tree' linear kernel seemed to perform the best, thus we perform it and hope to outperform its predecessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C parameter: {'C': 4.4499999999999975} \n",
      "\n",
      "[[47  5]\n",
      " [ 9 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        52\n",
      "           1       0.86      0.77      0.81        39\n",
      "\n",
      "    accuracy                           0.85        91\n",
      "   macro avg       0.85      0.84      0.84        91\n",
      "weighted avg       0.85      0.85      0.84        91\n",
      "\n",
      "ROC AUC score: 0.8365384615384616\n",
      "Test accuracy: 0.8461538461538461\n",
      "Train accuracy: 0.8584905660377359\n"
     ]
    }
   ],
   "source": [
    "c = np.arange(1, 7, 0.15)\n",
    "param_grid = {'C': c}\n",
    "\n",
    "svc = SVC(cache_size = 500, kernel = 'linear',\n",
    "          max_iter = -1, probability = True)\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv = 5, iid = True)\n",
    "svc_cv.fit(X_train, y_train)\n",
    "y_pred = svc_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C parameter: {} \\n\".format(svc_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(svc_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(svc_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"FS SVM linear\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": svc_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of linear SVM, the feature selection method yielded worse results than before. Then number of false negatives increase as well as the number of false positives. In that case, I would like to see whether the tendency is spread across other types of SVM kernels. Thus we will perform also the poly and rbf versions of SVM. The poly version is next on the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C parameter: {'C': 2.499999999999999, 'degree': 2} \n",
      "\n",
      "[[50  2]\n",
      " [12 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88        52\n",
      "           1       0.93      0.69      0.79        39\n",
      "\n",
      "    accuracy                           0.85        91\n",
      "   macro avg       0.87      0.83      0.84        91\n",
      "weighted avg       0.86      0.85      0.84        91\n",
      "\n",
      "ROC AUC score: 0.826923076923077\n",
      "Test accuracy: 0.8461538461538461\n",
      "Train accuracy: 0.8537735849056604\n"
     ]
    }
   ],
   "source": [
    "c = np.arange(1, 7, 0.15)\n",
    "degree = np.arange(2, 6, 1)\n",
    "param_grid = {'C': c, 'degree': degree}\n",
    "\n",
    "svc = SVC(cache_size = 500, kernel = 'poly',\n",
    "          max_iter = -1, probability = True, gamma = 'auto')\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv = 5, iid = True)\n",
    "svc_cv.fit(X_train, y_train)\n",
    "y_pred = svc_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C parameter: {} \\n\".format(svc_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(svc_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(svc_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"FS SVM poly\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": svc_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of poly kernel the results didn't change at all, which is quite interesting. Last SVM method is the one using rbf kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C parameter: {'C': 3.0500000000000016} \n",
      "\n",
      "[[49  3]\n",
      " [ 7 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        52\n",
      "           1       0.91      0.82      0.86        39\n",
      "\n",
      "    accuracy                           0.89        91\n",
      "   macro avg       0.89      0.88      0.89        91\n",
      "weighted avg       0.89      0.89      0.89        91\n",
      "\n",
      "ROC AUC score: 0.8814102564102564\n",
      "Test accuracy: 0.8901098901098901\n",
      "Train accuracy: 0.8820754716981132\n"
     ]
    }
   ],
   "source": [
    "c = np.arange(1, 4, 0.05)\n",
    "param_grid = {'C': c}\n",
    "\n",
    "svc = SVC(cache_size = 500, kernel = 'rbf',\n",
    "          max_iter = -1, probability = True, gamma = 'auto')\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv = 5, iid = True)\n",
    "svc_cv.fit(X_train, y_train)\n",
    "y_pred = svc_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C parameter: {} \\n\".format(svc_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(svc_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(svc_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"FS SVM rbf\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": svc_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the results improved again, so we had all possible outcomes with the SVMs. Linear got worse, poly stayed the same and rbf got better. It achieved the ElasticNet's level of proficiency, scoring the exact same predictions as mentioned regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS Logistic Regression\n",
    "Last on the list is logistic regression. We will do the Lasso or Ridge parameter grid search again and then try with ElasticNet and see what are the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C and penalty parameters: {'C': 33.9322177189533, 'penalty': 'l1'} \n",
      "\n",
      "[[47  5]\n",
      " [ 7 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89        52\n",
      "           1       0.86      0.82      0.84        39\n",
      "\n",
      "    accuracy                           0.87        91\n",
      "   macro avg       0.87      0.86      0.86        91\n",
      "weighted avg       0.87      0.87      0.87        91\n",
      "\n",
      "ROC AUC score: 0.8621794871794871\n",
      "Test accuracy: 0.8681318681318682\n",
      "Train accuracy: 0.8632075471698113\n"
     ]
    }
   ],
   "source": [
    "c_log = np.logspace(-5, 5, 50)\n",
    "param_grid = {'C': c_log, 'penalty': ['l1','l2']}\n",
    "\n",
    "lr = LogisticRegression(solver = 'saga', max_iter = 100000)\n",
    "lr_cv = GridSearchCV(lr, param_grid, cv = 5, iid = True)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "y_pred = lr_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C and penalty parameters: {} \\n\".format(lr_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(lr_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(lr_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"FS Logreg Lasso\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": lr_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again the results are slightly worse than for its previous counterpart, achieving one less correct prediction for both TPs and TNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned C and l1_ratio parameters: {'C': 33.9322177189533, 'l1_ratio': 0.0} \n",
      "\n",
      "[[47  5]\n",
      " [ 7 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89        52\n",
      "           1       0.86      0.82      0.84        39\n",
      "\n",
      "    accuracy                           0.87        91\n",
      "   macro avg       0.87      0.86      0.86        91\n",
      "weighted avg       0.87      0.87      0.87        91\n",
      "\n",
      "ROC AUC score: 0.8621794871794871\n",
      "Test accuracy: 0.8681318681318682\n",
      "Train accuracy: 0.8632075471698113\n"
     ]
    }
   ],
   "source": [
    "c_log = np.logspace(-5, 5, 50)\n",
    "l1_ratio = np.arange(0, 1.01, 0.1)\n",
    "param_grid = {'C': c_log, 'l1_ratio': l1_ratio}\n",
    "\n",
    "lr = LogisticRegression(solver = 'saga', penalty = 'elasticnet', max_iter = 10000000)\n",
    "lr_cv = GridSearchCV(lr, param_grid, cv = 5, iid = True)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "y_pred = lr_cv.predict(X_test)\n",
    "\n",
    "print(\"Tuned C and l1_ratio parameters: {} \\n\".format(lr_cv.best_params_))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score: {}\" .format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Test accuracy: {}\" .format(lr_cv.score(X_test, y_test)))\n",
    "print(\"Train accuracy: {}\" .format(lr_cv.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(pd.DataFrame({\"Model\": \"FS Logreg ElasticNet\", \n",
    "                             \"ROC AUC score\": roc_auc_score(y_test, y_pred),\n",
    "                             \"Accuracy\": lr_cv.score(X_test, y_test)},\n",
    "                             index=[0]),\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet also yielded slightly worse results, again choosing to not take Lasso into account and sticking with Ridge. The 'C' parameter however is bigger than previously, but the prediction power is smaller. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Let's take a look at the results we obtained from each model and analyze some of their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model  ROC AUC score  Accuracy\n",
      "         Logreg Lasso       0.884615  0.890110\n",
      "    Logreg ElasticNet       0.881410  0.890110\n",
      "           FS SVM rbf       0.881410  0.890110\n",
      "      FS Logreg Lasso       0.862179  0.868132\n",
      " FS Logreg ElasticNet       0.862179  0.868132\n",
      "           SVM linear       0.855769  0.868132\n",
      "             FS KNN-3       0.849359  0.857143\n",
      "              SVM rbf       0.839744  0.846154\n",
      "        FS SVM linear       0.836538  0.846154\n",
      "             SVM poly       0.826923  0.846154\n",
      "          FS SVM poly       0.826923  0.846154\n",
      "                KNN-6       0.817308  0.835165\n"
     ]
    }
   ],
   "source": [
    "results_sort = results.sort_values(by=['ROC AUC score'], ascending = False)\n",
    "print(results_sort.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this results table we can see that the Logistic Regression with Lasso penalty performed the best in terms of both  ROC AUC score and test set accuracy (on par with ElasticNet). If we get back to the classification report of the aforementioned Logistic regression model we will see that it achieved high recall of 0.92 for healthy people and lower for ill people (0.85). This means our model is better at detecting people without disease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as SVM models are concerned, both linear and rbf SVMs were noticeably worse at detecting TNs and slightly better at detecting TPs. So all in all they were less useful than Logreg model. SVM poly however achieved even higher recall value for 0's than aforementioned model and detected 96% of people without disease correctly. The drawback to this was much worse detection of disease presence. But this model could be used specifically just to detect healthy, due to it's high precision in that department."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial KNN model with 6 neighbours performed the worst of all tested models, both in terms of accuracy and ROC AUC score. Its power of correctly detection healthy people was on par with the best models but it stood out in terms of detecting sick patients. 12 out of 39 sick were wrongly classified as healthy which is an abysmal number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection found out that some of the variables were not contributing much to the explanation of our target variable, thus in the next step I decided to leave them out and see if it impoves any of the models. In case of KNN it improved the model significantly. It was now (with 3 neighbours) able to 'compete' with previous models. All in all, though, the predictions were quite mediocre and earned a place in the middle of the table. The case with SVMs was quite interesting as for linear kernel the performance dropped, for poly didn't change at all and improved for rbf, achieving ex aequo second best result with ElasticNet. In terms of regressions, the feature selection method decreased the performance of both methods. Using feature selected data, both regressions scored the same results and predictions, which was a relatively bigger drop in performance for Lasso regression. Summing up, feature selection was a mixed bag, improving some, worsening some predictions, but reduced the number of variables needed, so in case we lacked the information provided by the omitted variables, this somehow might prove useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
